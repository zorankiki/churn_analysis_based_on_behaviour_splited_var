{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spots that are always excluded:\n",
    "##### Test spots\n",
    "##### Spots marked as problematic\n",
    "##### Suscpicious for analysis == 'Yes' spots\n",
    "##### Fake Sale spots: This means that Reason for Cancelling Survey is any combination which contains 'Fake Sale'\n",
    "##### Spots whose start date was before 2018\n",
    "\n",
    "\n",
    "## CAN CANCEL:\n",
    "##### Spots which cancelled more than 2 months before their Available Cancellation Date are excluded\n",
    "##### Spots whose Available Cancellation Date is 2 or more months after the date of analysis\n",
    "##### Months during which spots couldn't have cancelled according to the above conditions\n",
    "\n",
    "## wo CB sets:\n",
    "##### Closed Business, Sold Business and Non-payment spots are excluded. This means Reason for Cancelling Survey is any combination which contains 'Closed Business', 'Closed/Sold Business', 'Sold Business', 'Sold/Closed Business' or 'Non-payment'\n",
    "## canc conf event\n",
    "##### Spots for which Date Cancellation Confirmed is more than 60 days after Date Cancellation Requested\n",
    "\n",
    "#### ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import importlib\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import get_started_doing_something_variables\n",
    "import prepare_for_the_models\n",
    "import fit_tv_cox_models\n",
    "import read_a_combination_of_variables\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "#### Helpers ####\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from helpers.s3_bucket_utils import S3BucketUtils\n",
    "from helpers import db_utils\n",
    "from helpers import settings\n",
    "\n",
    "bucket = S3BucketUtils()\n",
    "################\n",
    "\n",
    "import calculate_all_vars_for_churn_prediction\n",
    "import churn_risk_calculation_test\n",
    "import churn_risk_calculation\n",
    "import model_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the yaml file with a list of parameters needed for the report\n",
    "with open(r'./parameters/started_doing_something_report_parameters.yaml') as file:\n",
    "    parameters = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "date_of_analysis = parameters['date_of_analysis']\n",
    "date_dir = date_of_analysis.replace('-', '_')\n",
    "### name of the data directory ###\n",
    "churn_based_on_behaviour_dir = parameters['churn_based_on_behaviour_dir']\n",
    "hs_list_filename = parameters['hs_list_filename']\n",
    "hs_list_path = 'churn_analysis/data/'+date_dir+'/'+hs_list_filename\n",
    "\n",
    "prediction_months = parameters['prediction_months']\n",
    "### penalizer value when fitting the models ###\n",
    "penalizer = parameters['penalizer']\n",
    "### model type ###\n",
    "model_type = parameters['model_type']\n",
    "### coefficient and p values when dropping unsignificant variables ###\n",
    "coefficient_limit_for_numerical_vars = parameters['coefficient_limit_for_numerical_vars']\n",
    "coefficient_limit_for_cat_vars = parameters['coefficient_limit_for_cat_vars']\n",
    "p_limit = parameters['p_limit']\n",
    "additional_higher_p_limit = parameters['additional_higher_p_limit']\n",
    "additional_lower_p_limit = parameters['additional_lower_p_limit']\n",
    "\n",
    "# read the yaml file with data set parameters #\n",
    "# data_set_name = input('Data set name: ')\n",
    "data_set_name = 'ALL_spots_with_CB_cancellation_confirmed'\n",
    "with open(r'./parameters/data_sets.yaml') as file:\n",
    "    data_sets_parameters = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "spots_set = data_sets_parameters[data_set_name]['spots_set']\n",
    "with_wo_CB = data_sets_parameters[data_set_name]['with_wo_CB']\n",
    "event_date_full_name = data_sets_parameters[data_set_name]['event_date_type']\n",
    "\n",
    "if with_wo_CB == 'with_CB':\n",
    "    with_wo_CB_boolean = True\n",
    "else:\n",
    "    with_wo_CB_boolean = False\n",
    "\n",
    "if event_date_full_name == 'cancellation_requested':\n",
    "    event_date = 'canc_req'\n",
    "elif event_date_full_name == 'cancellation_confirmed':\n",
    "    event_date = 'canc_conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### base columns ##### \n",
    "base_cols = ['spot_id',\\\n",
    "            'time',\\\n",
    "            'event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Model 0: all variables - prepare data for the model ####\n",
    "cols_to_use = read_a_combination_of_variables.\\\n",
    "main(model_number=0, dir_name='combinations_of_variables_that_are_not_dependent/')\n",
    "#### get behavioural variables ####\n",
    "(variables_to_use_for_the_model, did_something_last_month_vars, did_something_before_and_didnt_last_month_vars) = \\\n",
    "get_started_doing_something_variables.main(date_of_analysis=date_of_analysis, variables_to_use_for_the_model=cols_to_use)\n",
    "cols = base_cols + variables_to_use_for_the_model + \\\n",
    "did_something_before_and_didnt_last_month_vars + did_something_last_month_vars\n",
    "\n",
    "data_all_spots = \\\n",
    "calculate_all_vars_for_churn_prediction.\\\n",
    "get_data_for_the_MV_Cox_model(date_of_analysis=date_of_analysis,\\\n",
    "                              hs_filename=hs_list_filename,\\\n",
    "                              spots_set=spots_set,\\\n",
    "                              with_wo_CB=with_wo_CB,\\\n",
    "                              event_date=event_date, columns=cols,\\\n",
    "                              data_dir=churn_based_on_behaviour_dir)\n",
    "\n",
    "#### get data for the model ###\n",
    "(data, base_df, df_timeline_all_vars) = \\\n",
    "prepare_for_the_models.get_data_for_the_MV_Cox_model(date_of_analysis=date_of_analysis, spots_set=spots_set, \\\n",
    "                            with_wo_CB=with_wo_CB, event_date=event_date, columns=cols, data_dir=churn_based_on_behaviour_dir,\\\n",
    "                            C = 100)\n",
    "    \n",
    "model_numbers = \\\n",
    "read_a_combination_of_variables.get_a_list_of_model_numbers(dir_name='combinations_of_variables_that_are_not_dependent/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly_used_inquiries_models = read_a_combination_of_variables.\\\n",
    "# get_properly_used_inquiries_model_names_and_numbers(dir_name='combinations_of_variables_that_are_not_dependent/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine which models are not already fit ##\n",
    "import models_to_be_fit\n",
    "num_of_p_values = 1\n",
    "num_of_prediction_months = len(prediction_months)\n",
    "churn_risk_prediction_exports = 'data/'+date_dir+'/exports/churn_risk_prediction/'+model_type+'/'\n",
    "coefficients_and_pvalues_exports = 'data/'+date_dir+'/exports/coefficients_and_pvalues/'+model_type+'/'\n",
    "(already_fit, yet_to_be_fit) = models_to_be_fit.main(model_numbers=model_numbers,\\\n",
    "                                                     model_type=model_type,\\\n",
    "                                                     date_dir=date_dir,\\\n",
    "                                                     churn_risk_prediction_exports=churn_risk_prediction_exports,\\\n",
    "                                                     coefficients_and_pvalues_exports=coefficients_and_pvalues_exports,\\\n",
    "                                                     data_set_name=data_set_name,\\\n",
    "                                                     num_of_p_values=num_of_p_values,\\\n",
    "                                                     num_of_prediction_months=num_of_prediction_months)\n",
    "\n",
    "# for model_number in properly_used_inquiries_models['model_number'].unique():\n",
    "for model_number in yet_to_be_fit:\n",
    "    cols_to_use = read_a_combination_of_variables.\\\n",
    "    main(model_number=model_number, dir_name='combinations_of_variables_that_are_not_dependent/')\n",
    "    \n",
    "    print(sorted(cols_to_use))\n",
    "    \n",
    "    model_name = \\\n",
    "    read_a_combination_of_variables.get_model_names(model_number=model_number, \\\n",
    "                                                    dir_name='combinations_of_variables_that_are_not_dependent/')\n",
    "    display(Markdown(\"# Model \"+ str(model_number) + \": \" + model_name))\n",
    "\n",
    "    #### get behavioural variables ####\n",
    "    (variables_to_use_for_the_model, did_something_last_month_vars, did_something_before_and_didnt_last_month_vars) = \\\n",
    "    get_started_doing_something_variables.main(date_of_analysis=date_of_analysis, variables_to_use_for_the_model=cols_to_use)\n",
    "    cols = variables_to_use_for_the_model + \\\n",
    "    did_something_before_and_didnt_last_month_vars + did_something_last_month_vars\n",
    "\n",
    "    #### data for the model ###\n",
    "    df_timeline = df_timeline_all_vars.copy()\n",
    "    vars_that_stay = ['spot_id', 'start', 'stop', 'event']+\\\n",
    "    [x for x in cols if x not in base_cols]+\\\n",
    "    [x for x in df_timeline.columns if 'spot_category_' in x or 'metro_area_' in x]\n",
    "    df_timeline.drop([x for x in df_timeline.columns if x not in vars_that_stay], axis = 1, inplace = True)\n",
    "\n",
    "    ### variables to skip ###\n",
    "    df_timeline.isnull().sum().sum() #OK\n",
    "    skip_vars = list((df_timeline!=0).sum()[(df_timeline!=0).sum()==0].index)\n",
    "    skip_vars\n",
    "\n",
    "    ctv = fit_tv_cox_models.fit_the_models_and_print_summaries(df_timeline=df_timeline, base_df=base_df, \\\n",
    "                                                         date_of_analysis=date_of_analysis, model_type=model_type, \\\n",
    "                                                         variables_to_use_for_the_model=cols_to_use,\\\n",
    "                                                         coefficient_limit_for_numerical_vars=coefficient_limit_for_numerical_vars, \\\n",
    "                                                         coefficient_limit_for_cat_vars=coefficient_limit_for_cat_vars, p_limit=p_limit, \\\n",
    "                                                         additional_higher_p_limit=additional_higher_p_limit, \\\n",
    "                                                         additional_lower_p_limit=additional_lower_p_limit,\\\n",
    "                                                         skip_vars=skip_vars, penalizer=penalizer)\n",
    "\n",
    "    ### save coefs and p values for p < 0.2 ###\n",
    "    fit_tv_cox_models.save_results(df = ctv.summary.reset_index(), date_of_analysis = date_of_analysis, \\\n",
    "                                   data_dir = churn_based_on_behaviour_dir, dir_name='exports/coefficients_and_pvalues',\\\n",
    "                 results_name = 'coef_and_pvalues', spots_set = spots_set,\\\n",
    "                 with_wo_CB = with_wo_CB, event_date_type = event_date_full_name, p_limit=0.2, model_number=model_number,\\\n",
    "                                  model_type = model_type)\n",
    "    \n",
    "    churn_risk_calculation.calculate_churn_risk(date_of_analysis = date_of_analysis, df_timeline = df_timeline, \\\n",
    "                                            vars_ = list(ctv.summary.index), data_all_spots = data_all_spots, ctv = ctv, \\\n",
    "                                            model_type = model_type, model_number = model_number,\\\n",
    "                                            with_add_vars = False, p_limit = p_limit,\\\n",
    "                                            event_date_type=event_date_full_name, spots_set = spots_set, with_wo_CB=with_wo_CB)\n",
    "    \n",
    "    for prediction_month in prediction_months:\n",
    "        testing_results = model_testing.\\\n",
    "        get_testing_results(date_of_analysis=date_of_analysis,\\\n",
    "                            df_timeline=df_timeline.copy(), \\\n",
    "                            base_df = base_df.copy(),\\\n",
    "                            data_all_spots=data_all_spots.copy(), \\\n",
    "                            hs_list_path=hs_list_path,\\\n",
    "                            model_type=model_type,\\\n",
    "                            model_number=model_number,\\\n",
    "                            with_add_vars=False, p_limit=p_limit, event_date_type=event_date_full_name, \\\n",
    "                            prediction_month=prediction_month, ctv=ctv, spots_set=spots_set, \\\n",
    "                            with_wo_CB=with_wo_CB, penalizer=penalizer, test_with_req_canc_before=True)\n",
    "\n",
    "        model_testing.save_results(date_of_analysis=date_of_analysis,\\\n",
    "                               df=testing_results[0], \\\n",
    "                               results_name='testing_results', \\\n",
    "                               model_type=model_type,\\\n",
    "                               model_number=model_number,\\\n",
    "                               spots_set=spots_set,\\\n",
    "                               with_wo_CB=with_wo_CB,\\\n",
    "                               event_date_type=event_date_full_name,\\\n",
    "                               with_add_vars=False, p_limit=p_limit, prediction_month=prediction_month)\n",
    "        display(Markdown(\"## Model \"+ str(model_number) + \": testing results\"))\n",
    "        display(testing_results[0].set_index('index'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
