{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import important_variables\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#### Helpers ####\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from helpers.s3_bucket_utils import S3BucketUtils\n",
    "from helpers import db_utils\n",
    "from helpers import settings\n",
    "\n",
    "bucket = S3BucketUtils()\n",
    "################\n",
    "\n",
    "for_interpretation = {'model_started':{'did_something_last_X_months':'continued_vs_never_did', 'did_something_before_and_didnt_last_X_months':'stopped_vs_never_did'},\\\n",
    "                     'model_stopped':{'did_something_before':'stopped_vs_never_did', 'did_something_last_X_months':'continued_vs_stopped'}}\n",
    "\n",
    "### read model names and numbers ###\n",
    "model_names = bucket.\\\n",
    "load_csv_from_s3(file_name = 'churn_analysis_based_on_behaviour/combinations_of_variables_that_are_not_dependent/'+\\\n",
    "'model_names.csv')\n",
    "\n",
    "model_names['model_name'] = model_names['model_name'].map(lambda x: \\\n",
    "    list(map(lambda x: x.lstrip(' '), x.replace(\"'\", \"\").split(','))))\n",
    "model_names = model_names.explode('model_name')\n",
    "\n",
    "\n",
    "\n",
    "def add_month(date, m):\n",
    "    ddd = pd.to_datetime(date, format='%Y-%m-%d')\n",
    "    ddd2 = ddd + relativedelta(months=m)\n",
    "    return (str(ddd2))[0:10]\n",
    "\n",
    "def get_key_based_on_value_in_a_dict(dict_, value_of_interest):\n",
    "    for key, value in dict_.items():\n",
    "        if value == value_of_interest:\n",
    "            return key\n",
    "\n",
    "def get_var_type(var_name, first_var, second_var):\n",
    "    if var_name not in first_var.values() and var_name not in second_var.values():\n",
    "        return 'not_behavioural'\n",
    "    elif 'before' in var_name and 'last_month' not in var_name and 'months' not in var_name:\n",
    "        return 'did_something_before'\n",
    "    elif 'before' in var_name and 'didnt' in var_name:\n",
    "        return 'did_something_before_and_didnt_last_X_months'\n",
    "    elif 'before' not in var_name:\n",
    "        return 'did_something_last_X_months'\n",
    "\n",
    "def get_base_var_names(df, first_var, second_var):\n",
    "    df['variable_base_name'] = df['variable']\n",
    "    df['variable_type'] = df['variable'].apply(lambda x: get_var_type(var_name=x, first_var=first_var, second_var=second_var))\n",
    "    for var_ in first_var.values():\n",
    "        if var_ in df['variable'].unique():\n",
    "            df.loc[(df['variable']==var_),  'variable_base_name'] = get_key_based_on_value_in_a_dict(dict_=first_var, \\\n",
    "                                                                                                    value_of_interest=var_)\n",
    "            \n",
    "    for var_ in second_var.values():\n",
    "        if var_ in df['variable'].unique():\n",
    "            df.loc[(df['variable']==var_),  'variable_base_name'] = get_key_based_on_value_in_a_dict(dict_=second_var, \\\n",
    "                                                                                                    value_of_interest=var_)\n",
    "            \n",
    "    return df\n",
    "\n",
    "def check_the_vars_with_the_same_interpretation(x):\n",
    "    if len(x)>1:\n",
    "        if x['interpretation'].iloc[0]==x['interpretation'].iloc[1]:\n",
    "            if x['exp(coef) - AVERAGE'].iloc[0]>1 and x['exp(coef) - AVERAGE'].iloc[1]<1:\n",
    "                return True\n",
    "            elif x['exp(coef) - AVERAGE'].iloc[0]<1 and x['exp(coef) - AVERAGE'].iloc[1]>1: \n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def model_to_choose_from(x):\n",
    "    return x[x['p value - AVERAGE']==min(x['p value - AVERAGE'])]['model'].iloc[0]\n",
    "\n",
    "\n",
    "def get_data_type(df, var_):\n",
    "    if df[var_].nunique()==2 and 1 in df[var_].unique() and 0 in df[var_].unique():\n",
    "        return 'categorical'\n",
    "    else:\n",
    "        return 'numerical'\n",
    "\n",
    "def get_perc_of_spots(df, var_, var_type):\n",
    "    if var_type=='numerical':\n",
    "        return np.nan\n",
    "    elif var_type=='categorical':\n",
    "        return round(100*(df[(df[var_]==1)]['spot_id'].nunique()/df['spot_id'].nunique()), 2)\n",
    "    \n",
    "def get_perc_of_spots_last_month(df, var_, var_type, last_month):\n",
    "    if var_type=='numerical':\n",
    "        return np.nan\n",
    "    elif var_type=='categorical':\n",
    "        return round(100*(df[(df[var_]==1)&\\\n",
    "                            (df['left_limit']==last_month)]['spot_id'].nunique()/df[df['left_limit']==last_month]['spot_id'].nunique()), 2)\n",
    "    \n",
    "    \n",
    "def get_coef_and_p_for_a_specific_model(var_base_name, var_, model, spots_set, model_names, date_dir):\n",
    "    \n",
    "    if ('changed_inquiry_status' in var_base_name):\n",
    "        with open(r'./parameters/for_properly_used_inquiries_vars.yaml') as file:\n",
    "            for_properly_used_inquiries_vars = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "        var_base_name = for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][var_base_name]\n",
    "    \n",
    "    if var_base_name in model_names['model_name'].unique():\n",
    "        model_number = \\\n",
    "        model_names[(model_names['model_name'].apply(lambda x: var_base_name in x))]['model_number'].values[0]\n",
    "    else:\n",
    "        model_number = 1\n",
    "    if model == 'model_started':\n",
    "        coefs_and_p_values = \\\n",
    "        bucket.load_csv_from_s3(file_name='churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/coefficients_and_pvalues/'+\\\n",
    "                               'started_doing_something/model_'+str(model_number)+'/coef_and_pvalues_'+spots_set+'_p_below_0_2.csv')\n",
    "    else:\n",
    "        coefs_and_p_values = \\\n",
    "        bucket.load_csv_from_s3(file_name='churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/coefficients_and_pvalues/'+\\\n",
    "                               'stopped_doing_something/model_'+str(model_number)+'/coef_and_pvalues_'+spots_set+'_p_below_0_2.csv')\n",
    "        \n",
    "    if var_ in coefs_and_p_values['covariate'].unique():\n",
    "        return coefs_and_p_values[(coefs_and_p_values['covariate']==var_)][['exp(coef)', 'p']].\\\n",
    "            apply(lambda x: (round(x[0], 4), round(x[1], 3)), axis = 1).values[0]\n",
    "#         if coefs_and_p_values[(coefs_and_p_values['covariate']==var_)]['p'].values[0]<=0.05:\n",
    "#             return coefs_and_p_values[(coefs_and_p_values['covariate']==var_)][['exp(coef)', 'p']].\\\n",
    "#             apply(lambda x: (round(x[0], 4), round(x[1], 3)), axis = 1).values[0]\n",
    "#         else:\n",
    "#             return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# def get_coef_and_p_for_a_specific_model_for_non_behavioural_vars(var_base_name, var_, model, spots_set, model_names, date_dir):\n",
    "#     for model_number in model_names['model_number'].unique()[1:]:\n",
    "#         if model == 'model_started':\n",
    "#             coefs_and_p_values = \\\n",
    "#             bucket.load_csv_from_s3(file_name='churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/coefficients_and_pvalues/'+\\\n",
    "#                                    'started_doing_something/model_'+str(model_number)+'/coef_and_pvalues_'+spots_set+'_p_below_0_2.csv')\n",
    "#         else:\n",
    "#             coefs_and_p_values = \\\n",
    "#             bucket.load_csv_from_s3(file_name='churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/coefficients_and_pvalues/'+\\\n",
    "#                                'stopped_doing_something/model_'+str(model_number)+'/coef_and_pvalues_'+spots_set+'_p_below_0_2.csv')\n",
    "#         if var_ in coefs_and_p_values['covariate'].unique():\n",
    "#             if coefs_and_p_values[(coefs_and_p_values['covariate']==var_)]['p'].values[0]<=0.05:\n",
    "#                 model_name = model_names[model_names['model_number']==model_number]['model_name'].values[0]\n",
    "#                 return coefs_and_p_values[(coefs_and_p_values['covariate']==var_)][['exp(coef)', 'p']].\\\n",
    "#                       apply(lambda x: (round(x[0], 4), round(x[1], 3), 'model_for_'+str(model_name)), axis = 1).values[0]\n",
    "#     return np.nan\n",
    "    \n",
    "\n",
    "\n",
    "def main(date_of_analysis):\n",
    "    date_dir = date_of_analysis.replace('-', '_')\n",
    "    last_month = add_month(date_of_analysis, -1)\n",
    "    \n",
    "    for file_name in ['all_significant_variables_sorted_by_p_value.csv',\\\n",
    "                 'not_significant_variables_with_p_below_0_2_sorted_by_p_value.csv']:\n",
    "        combined_export = []\n",
    "        for model_type in ['started_doing_something', 'stopped_doing_something']:\n",
    "            (first_var, second_var) = \\\n",
    "            important_variables.get_pairs_of_variables(churn_based_on_behaviour_dir='churn_analysis_based_on_behaviour/',\\\n",
    "                                                   date_dir=date_dir, model_type=model_type)\n",
    "\n",
    "            df_important_vars = \\\n",
    "            pd.read_csv('data/'+date_dir+'/exports/'+model_type+'/'+file_name)\n",
    "\n",
    "            df_important_vars['model'] = 'model_'+model_type.split('_')[0]\n",
    "\n",
    "            df_important_vars = get_base_var_names(df=df_important_vars, first_var=first_var, second_var=second_var)\n",
    "\n",
    "            combined_export.append(df_important_vars)\n",
    "\n",
    "        combined_export = \\\n",
    "        pd.concat([combined_export[0], combined_export[1]], axis = 0)\n",
    "        combined_export.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        combined_export['interpretation'] = 'not a behavioural variable'\n",
    "        combined_export['interpretation'] = \\\n",
    "        combined_export[['model', 'variable_type']].apply(lambda x: for_interpretation[x['model']][x['variable_type']] if x['variable_type']!='not_behavioural' else x['variable_type'], axis = 1)\n",
    "\n",
    "        combined_export = combined_export.merge(combined_export.groupby(['variable_base_name', 'variable_type', 'interpretation'])[['exp(coef) - AVERAGE', 'interpretation']].\\\n",
    "        apply(lambda x: check_the_vars_with_the_same_interpretation(x)).reset_index().rename(columns = {0:'different_sign'}),\\\n",
    "                          on = ['variable_base_name', 'variable_type', 'interpretation'])\n",
    "\n",
    "        if len(combined_export[(combined_export['different_sign']==True)])>0:\n",
    "            print('THERE ARE VARIABLE THAT REPRESENT THE SAME THING BUT HAVE A DIFFERENT SIGN!!!')\n",
    "        else:\n",
    "            combined_export.drop(combined_export[(combined_export['model']=='model_stopped')&\\\n",
    "                                                (combined_export['variable_type']=='did_something_before')].index, inplace = True)\n",
    "\n",
    "            duplicate_vars = \\\n",
    "            combined_export[combined_export['interpretation']=='not_behavioural'].groupby('variable')['model'].nunique()[combined_export[combined_export['interpretation']=='not_behavioural'].groupby('variable')['model'].nunique()>1].\\\n",
    "            reset_index()['variable'].unique()\n",
    "\n",
    "            combined_export.reset_index(drop = True, inplace = True)\n",
    "\n",
    "            df_duplicate_vars = combined_export[(combined_export['variable'].isin(duplicate_vars))].\\\n",
    "            groupby('variable')[['model', 'p value - AVERAGE']].apply(lambda x: model_to_choose_from(x)).\\\n",
    "            reset_index().rename(columns = {0:'model_to_choose_from'})\n",
    "\n",
    "            combined_export = combined_export.merge(df_duplicate_vars, on = ['variable'], how = 'left')\n",
    "\n",
    "            combined_export.drop(combined_export[(combined_export['variable'].isin(duplicate_vars))&\\\n",
    "                                                (combined_export['model']!=combined_export['model_to_choose_from'])].index, inplace = True)\n",
    "\n",
    "        combined_export = combined_export[['variable_base_name', 'variable_type', 'model', 'variable', 'interpretation', 'exp(coef) - AVERAGE', 'p value - AVERAGE']].\\\n",
    "        sort_values(['p value - AVERAGE'])\n",
    "        combined_export.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        combined_export.loc[(combined_export['interpretation']=='not_behavioural'), 'interpretation'] = np.nan\n",
    "\n",
    "        if not os.path.exists('data/'+date_dir+'/exports/important_variables/'):\n",
    "            os.makedirs('data/'+date_dir+'/exports/important_variables/')\n",
    "        combined_export.\\\n",
    "        to_csv('data/'+date_dir+'/exports/important_variables/'+file_name, index = False)\n",
    "        bucket.store_csv_to_s3(data_frame = combined_export, \\\n",
    "            file_name = file_name, \\\n",
    "            dir = '/churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/important_variables/')\n",
    "\n",
    "        if file_name == 'all_significant_variables_sorted_by_p_value.csv':\n",
    "            sign_vars = combined_export\n",
    "            sign_vars['important_variables_group'] = 'significant_vars'\n",
    "        else:\n",
    "            not_sign_p_below_0_2_vars = combined_export\n",
    "            not_sign_p_below_0_2_vars['important_variables_group'] = 'not_significant_p_below_0_2'\n",
    "            \n",
    "    \n",
    "    behavioural_sign_vars_base_names = sign_vars[sign_vars['interpretation'].notnull()]['variable_base_name'].unique()\n",
    "\n",
    "    important_vars = \\\n",
    "    pd.concat([sign_vars, not_sign_p_below_0_2_vars[(not_sign_p_below_0_2_vars['interpretation'].notnull())&\\\n",
    "                             (not_sign_p_below_0_2_vars['variable_base_name'].\\\n",
    "                             isin(behavioural_sign_vars_base_names))]], axis = 0)\n",
    "    important_vars.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    spots_sets=['ALL', 'CAN_CANCEL']\n",
    "    with_wo_CB_options=['with_CB', 'wo_CB']\n",
    "    event_date_full_names=['cancellation_confirmed', 'cancellation_requested']\n",
    "\n",
    "#     all_spots_sets = []\n",
    "#     for spots_set in spots_sets:\n",
    "#         for with_wo_CB in with_wo_CB_options:\n",
    "#             for event_date_full_name in event_date_full_names:\n",
    "#                 if event_date_full_name == 'cancellation_requested':\n",
    "#                     event_date = 'canc_req'\n",
    "#                 elif event_date_full_name == 'cancellation_confirmed':\n",
    "#                     event_date = 'canc_conf'\n",
    "#                 all_spots_sets.append(spots_set+'_spots_'+with_wo_CB+'_'+event_date)\n",
    "\n",
    "    all_spots_sets = ['ALL_spots_with_CB_canc_req',\\\n",
    "                     'CAN_CANCEL_spots_wo_CB_canc_req']\n",
    "\n",
    "\n",
    "    cols_to_export = []\n",
    "    for set_ in all_spots_sets:\n",
    "        cols_to_export.append('%_of_'+set_)\n",
    "        cols_to_export.append('last_month_%_of_'+set_)\n",
    "\n",
    "        df = bucket.load_csv_from_s3(file_name = 'churn_analysis_based_on_behaviour/data/' + date_dir + \\\n",
    "                    '/exports/data_used_for_each_model/data_tv_'+set_+'.csv')\n",
    "        important_vars['type'] = important_vars['variable'].apply(lambda x: get_data_type(df, x))\n",
    "\n",
    "        important_vars['%_of_'+set_] = \\\n",
    "        important_vars[['variable', 'type']].apply(lambda x: get_perc_of_spots(df, x['variable'], x['type']), axis = 1)\n",
    "\n",
    "        important_vars['last_month_%_of_'+set_] = \\\n",
    "        important_vars[['variable', 'type']].apply(lambda x: get_perc_of_spots_last_month(df, x['variable'], x['type'], last_month), axis = 1)\n",
    "\n",
    "\n",
    "    all_spots = [#'ALL_spots_with_CB_cancellation_confirmed',\\\n",
    "                 'ALL_spots_with_CB_cancellation_requested']\n",
    "    can_cancel_spots = [#'CAN_CANCEL_spots_wo_CB_cancellation_confirmed',\\\n",
    "                       'CAN_CANCEL_spots_wo_CB_cancellation_requested']\n",
    "\n",
    "    for spots_set in all_spots+can_cancel_spots:\n",
    "        important_vars[spots_set+'_exp(coef)_and_p_value'] = np.nan\n",
    "        important_vars[spots_set+'_exp(coef)_and_p_value'] = \\\n",
    "        important_vars[['variable_base_name', 'model', 'variable']].\\\n",
    "        apply(lambda x: get_coef_and_p_for_a_specific_model(var_base_name=x['variable_base_name'],\\\n",
    "                                                           var_=x['variable'],\\\n",
    "                                                           model=x['model'],\\\n",
    "                                                           spots_set=spots_set,\\\n",
    "                                                           model_names=model_names, date_dir=date_dir), axis = 1)\n",
    "#         important_vars.loc[important_vars['interpretation'].isnull(), spots_set+'_exp(coef)_and_p_value'] = \\\n",
    "#         important_vars.loc[important_vars['interpretation'].isnull(), ['variable_base_name', 'model', 'variable']].\\\n",
    "#         apply(lambda x: get_coef_and_p_for_a_specific_model_for_non_behavioural_vars(var_base_name=x['variable_base_name'],\\\n",
    "#                                                            var_=x['variable'],\\\n",
    "#                                                            model=x['model'],\\\n",
    "#                                                            spots_set=spots_set,\\\n",
    "#                                                            model_names=model_names, date_dir=date_dir), axis = 1)\n",
    "\n",
    "    important_vars[['model', 'variable', 'interpretation', 'important_variables_group', 'exp(coef) - AVERAGE',\\\n",
    "                   'p value - AVERAGE']+[x+'_exp(coef)_and_p_value' for x in all_spots+can_cancel_spots]+cols_to_export].sort_values(['variable', 'interpretation']).\\\n",
    "    to_csv('data/'+date_dir+'/exports/important_variables/important_variables_sorted_by_variable_name.csv',\\\n",
    "          index = False)\n",
    "    bucket.store_csv_to_s3(data_frame = important_vars[['model', 'variable', 'interpretation', 'important_variables_group', 'exp(coef) - AVERAGE',\\\n",
    "                   'p value - AVERAGE']+[x+'_exp(coef)_and_p_value' for x in all_spots+can_cancel_spots]+cols_to_export].sort_values(['variable', 'interpretation']), \\\n",
    "            file_name = 'important_variables_sorted_by_variable_name.csv', \\\n",
    "            dir = '/churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/important_variables/')\n",
    "    \n",
    "    return important_vars[['model', 'variable', 'interpretation', 'important_variables_group', 'exp(coef) - AVERAGE',\\\n",
    "                   'p value - AVERAGE']+[x+'_exp(coef)_and_p_value' for x in all_spots+can_cancel_spots]+cols_to_export].sort_values(['variable', 'interpretation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(r'./parameters/started_doing_something_report_parameters.yaml') as file:\n",
    "    model_params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "date_of_analysis = model_params['date_of_analysis']\n",
    "important_vars = main(date_of_analysis=date_of_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-02-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_of_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
