{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date of analysis: 2023-02-01\n"
     ]
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import important_variables\n",
    "\n",
    "#### Helpers ####\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from helpers.s3_bucket_utils import S3BucketUtils\n",
    "from helpers import db_utils\n",
    "from helpers import settings\n",
    "\n",
    "bucket = S3BucketUtils()\n",
    "################\n",
    "\n",
    "def add_month(date, m):\n",
    "    ddd = pd.to_datetime(date, format='%Y-%m-%d')\n",
    "    ddd2 = ddd + relativedelta(months=m)\n",
    "    return (str(ddd2))[0:10]\n",
    "\n",
    "# def get_key_based_on_value_in_a_dict(dict_, value_of_interest):\n",
    "#     for key, value in dict_.items():\n",
    "#         if value == value_of_interest:\n",
    "#             return key\n",
    "\n",
    "# def get_var_type(var_name, first_var_old, first_var_new, second_var_old, second_var_new):\n",
    "#     if var_name not in first_var_old.values() and var_name not in first_var_new.values() and var_name not in second_var_old.values() and var_name not in second_var_new.values():\n",
    "#         return 'not_behavioural'\n",
    "#     elif 'before' in var_name and 'last_month' not in var_name and 'months' not in var_name:\n",
    "#         return 'did_something_before'\n",
    "#     elif 'before' in var_name and 'didnt' in var_name:\n",
    "#         return 'did_something_before_and_didnt_last_X_months'\n",
    "#     elif 'before' not in var_name:\n",
    "#         return 'did_something_last_X_months'\n",
    "\n",
    "# def get_base_var_names(df, first_var, second_var):\n",
    "#     df['variable_base_name'] = df['variable']\n",
    "#     df['variable_type'] = df['variable'].apply(lambda x: get_var_type(var_name=x, first_var_old=first_var_old, first_var_new=first_var_new,\\\n",
    "#                                                                       second_var_old=second_var_old, second_var_new=second_var_new))\n",
    "#     for var_ in first_var.values():\n",
    "#         if var_ in df['variable'].unique():\n",
    "#             df.loc[(df['variable']==var_),  'variable_base_name'] = get_key_based_on_value_in_a_dict(dict_=first_var, \\\n",
    "#                                                                                                     value_of_interest=var_)\n",
    "            \n",
    "#     for var_ in second_var.values():\n",
    "#         if var_ in df['variable'].unique():\n",
    "#             df.loc[(df['variable']==var_),  'variable_base_name'] = get_key_based_on_value_in_a_dict(dict_=second_var, \\\n",
    "#                                                                                                     value_of_interest=var_)\n",
    "            \n",
    "#     return df\n",
    "\n",
    "date_of_analysis = input('Date of analysis: ')\n",
    "date_dir = date_of_analysis.replace('-', '_')\n",
    "\n",
    "previous_date_of_analysis = add_month(date_of_analysis, -1)\n",
    "previous_date_dir = previous_date_of_analysis.replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant_vars_file_name = 'all_significant_variables_sorted_by_variable_name.csv'\n",
    "# not_sign_p_below_0_2_vars_file_name = 'not_significant_variables_with_p_below_0_2_sorted_by_variable_name.csv'\n",
    "# all_important_vars_file_name = 'all_variables_with_p_below_0_2_sorted_by_variable_name.csv'\n",
    "\n",
    "# columns_order = ['variable_base_name',\\\n",
    "#                  'variable_type',\\\n",
    "#                 'variable NEW',\\\n",
    "#                 'variable OLD',\\\n",
    "#                 'exp(coef) - AVERAGE NEW',\\\n",
    "#                 'exp(coef) - AVERAGE OLD',\\\n",
    "#                 'p value - AVERAGE NEW',\\\n",
    "#                 'p value - AVERAGE OLD',\\\n",
    "#                 'important_variables_group NEW',\\\n",
    "#                 'important_variables_group OLD']\n",
    "\n",
    "\n",
    "# for model_type in ['started_doing_something', 'stopped_doing_something']:\n",
    "#     (first_var_old, second_var_old) = \\\n",
    "#     important_variables.get_pairs_of_variables(churn_based_on_behaviour_dir='churn_analysis_based_on_behaviour/',\\\n",
    "#                                            date_dir=previous_date_dir, model_type=model_type)\n",
    "    \n",
    "#     (first_var_new, second_var_new) = \\\n",
    "#     important_variables.get_pairs_of_variables(churn_based_on_behaviour_dir='churn_analysis_based_on_behaviour/',\\\n",
    "#                                            date_dir=date_dir, model_type=model_type)\n",
    "    \n",
    "#     sign_vars_old = \\\n",
    "#     pd.read_csv('data/'+previous_date_dir+'/exports/'+model_type+'/'+significant_vars_file_name)\n",
    "#     sign_vars_old = get_base_var_names(df=sign_vars_old, first_var=first_var_old, second_var=second_var_old)\n",
    "\n",
    "#     sign_vars_new = \\\n",
    "#     pd.read_csv('data/'+date_dir+'/exports/'+model_type+'/'+significant_vars_file_name)\n",
    "#     sign_vars_new = get_base_var_names(df=sign_vars_new, first_var=first_var_new, second_var=second_var_new)\n",
    "\n",
    "#     not_sign_p_below_0_2_vars_old = \\\n",
    "#     pd.read_csv('data/'+previous_date_dir+'/exports/'+model_type+'/'+not_sign_p_below_0_2_vars_file_name)\n",
    "#     not_sign_p_below_0_2_vars_old = \\\n",
    "#     get_base_var_names(df=not_sign_p_below_0_2_vars_old, first_var=first_var_old, second_var=second_var_old)\n",
    "\n",
    "#     not_sign_p_below_0_2_vars_new = \\\n",
    "#     pd.read_csv('data/'+date_dir+'/exports/'+model_type+'/'+not_sign_p_below_0_2_vars_file_name)\n",
    "#     not_sign_p_below_0_2_vars_new = \\\n",
    "#     get_base_var_names(df=not_sign_p_below_0_2_vars_new, first_var=first_var_new, second_var=second_var_new)\n",
    "\n",
    "#     all_important_vars_old = \\\n",
    "#     pd.read_csv('data/'+previous_date_dir+'/exports/'+model_type+'/'+all_important_vars_file_name)\n",
    "#     all_important_vars_old = \\\n",
    "#     get_base_var_names(df=all_important_vars_old, first_var=first_var_old, second_var=second_var_old)\n",
    "\n",
    "#     all_important_vars_old['important_variables_group'] = \\\n",
    "#     all_important_vars_old['variable'].apply(lambda x: 'significant_vars' if x in sign_vars_old['variable'].unique() else\\\n",
    "#                                             'not_significant_p_below_0_2')\n",
    "\n",
    "#     all_important_vars_new = \\\n",
    "#     pd.read_csv('data/'+date_dir+'/exports/'+model_type+'/'+all_important_vars_file_name)\n",
    "#     all_important_vars_new = \\\n",
    "#     get_base_var_names(df=all_important_vars_new, first_var=first_var_new, second_var=second_var_new)\n",
    "#     all_important_vars_new['important_variables_group'] = \\\n",
    "#     all_important_vars_new['variable'].apply(lambda x: 'significant_vars' if x in sign_vars_new['variable'].unique() else\\\n",
    "#                                             'not_significant_p_below_0_2')\n",
    "    \n",
    "#     for col in ['variable', 'exp(coef) - AVERAGE', 'p value - AVERAGE', 'important_variables_group']:\n",
    "#         sign_vars_old.rename(columns = {col:col+' OLD'}, inplace = True)\n",
    "#         sign_vars_new.rename(columns = {col:col+' NEW'}, inplace = True)\n",
    "\n",
    "#         not_sign_p_below_0_2_vars_old.rename(columns = {col:col+' OLD'}, inplace = True)\n",
    "#         not_sign_p_below_0_2_vars_new.rename(columns = {col:col+' NEW'}, inplace = True)\n",
    "\n",
    "#         all_important_vars_old.rename(columns = {col:col+' OLD'}, inplace = True)\n",
    "#         all_important_vars_new.rename(columns = {col:col+' NEW'}, inplace = True)\n",
    "        \n",
    "#     all_important_vars_comp = all_important_vars_new.merge(all_important_vars_old, on = ['variable_base_name', 'variable_type'],\\\n",
    "#                             how = 'outer')[columns_order]\n",
    "\n",
    "#     all_important_vars_comp.to_csv('data/'+date_dir+'/exports/'+model_type+'/all_important_variables_comparison.csv',\\\n",
    "#                               index = False)\n",
    "#     bucket.store_csv_to_s3(data_frame = all_important_vars_comp, \\\n",
    "#         file_name = 'all_important_variables_comparison.csv', \\\n",
    "#         dir = '/churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/'+model_type+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######## compare exports with variables from both models ############\n",
    "cols_to_export = ['model', \\\n",
    "                  'variable',\\\n",
    "                  'interpretation',\\\n",
    "                  'exp(coef) - AVERAGE NEW',\\\n",
    "                  'exp(coef) - AVERAGE OLD',\\\n",
    "                  'p value - AVERAGE NEW',\\\n",
    "                  'p value - AVERAGE OLD',\\\n",
    "                  'important_variables_group NEW',\\\n",
    "                 'important_variables_group OLD']\n",
    "\n",
    "significant_vars_file_name = 'all_significant_variables_sorted_by_p_value.csv'\n",
    "not_sign_p_below_0_2_vars_file_name = 'not_significant_variables_with_p_below_0_2_sorted_by_p_value.csv'\n",
    "\n",
    "sign_vars_new = \\\n",
    "pd.read_csv('data/'+date_dir+'/exports/important_variables/'+significant_vars_file_name)\n",
    "sign_vars_old = \\\n",
    "pd.read_csv('data/'+previous_date_dir+'/exports/important_variables/'+significant_vars_file_name)\n",
    "\n",
    "not_sign_p_below_0_2_vars_new = \\\n",
    "pd.read_csv('data/'+date_dir+'/exports/important_variables/'+not_sign_p_below_0_2_vars_file_name)\n",
    "not_sign_p_below_0_2_vars_old = \\\n",
    "pd.read_csv('data/'+previous_date_dir+'/exports/important_variables/'+not_sign_p_below_0_2_vars_file_name)\n",
    "\n",
    "sign_vars_new['important_variables_group'] = 'significant_vars'\n",
    "sign_vars_old['important_variables_group'] = 'significant_vars'\n",
    "\n",
    "not_sign_p_below_0_2_vars_new['important_variables_group'] = 'not_significant_p_below_0_2'\n",
    "not_sign_p_below_0_2_vars_old['important_variables_group'] = 'not_significant_p_below_0_2'\n",
    "\n",
    "all_important_vars_new = pd.concat([sign_vars_new, not_sign_p_below_0_2_vars_new], axis = 0)\n",
    "all_important_vars_new['interpretation'].fillna('not_behavioural', inplace = True)\n",
    "\n",
    "all_important_vars_old = pd.concat([sign_vars_old, not_sign_p_below_0_2_vars_old], axis = 0)\n",
    "all_important_vars_old['interpretation'].fillna('not_behavioural', inplace = True)\n",
    "\n",
    "for col in ['exp(coef) - AVERAGE', 'p value - AVERAGE', 'important_variables_group']:\n",
    "    all_important_vars_old.rename(columns = {col:col+' OLD'}, inplace = True)\n",
    "    all_important_vars_new.rename(columns = {col:col+' NEW'}, inplace = True)\n",
    "\n",
    "all_important_vars_comp = all_important_vars_new.merge(all_important_vars_old, on = ['model', 'variable', 'interpretation'],\\\n",
    "                            how = 'outer')\n",
    "all_important_vars_comp.reset_index(drop = True, inplace = True)\n",
    "all_important_vars_comp.loc[(all_important_vars_comp['interpretation']=='not_behavioural'), 'interpretation'] = np.nan\n",
    "\n",
    "bucket.store_csv_to_s3(data_frame = all_important_vars_comp[cols_to_export],\\\n",
    "        file_name = 'all_important_variables_comparison.csv', \\\n",
    "        dir = '/churn_analysis_based_on_behaviour/data/'+date_dir+'/exports/important_variables/')\n",
    "all_important_vars_comp[cols_to_export].to_csv('data/'+date_dir+'/exports/important_variables/all_important_variables_comparison.csv',\\\n",
    "                              index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model',\n",
       " 'variable',\n",
       " 'interpretation',\n",
       " 'exp(coef) - AVERAGE NEW',\n",
       " 'exp(coef) - AVERAGE OLD',\n",
       " 'p value - AVERAGE NEW',\n",
       " 'p value - AVERAGE OLD',\n",
       " 'important_variables_group NEW',\n",
       " 'important_variables_group OLD']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
