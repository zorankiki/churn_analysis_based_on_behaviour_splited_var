{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import get_started_doing_something_variables\n",
    "import get_stopped_doing_something_variables\n",
    "import prepare_for_the_models\n",
    "import read_a_combination_of_variables\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import get_all_vars\n",
    "import yaml\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from helpers.s3_bucket_utils import S3BucketUtils\n",
    "from helpers import settings\n",
    "\n",
    "bucket = S3BucketUtils()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "with open(r'./parameters/for_properly_used_inquiries_vars.yaml') as file:\n",
    "    for_properly_used_inquiries_vars = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "pd.set_option('display.max_colwidth', 5000)\n",
    "def add_month(date, m):\n",
    "    ddd = pd.to_datetime(date, format='%Y-%m-%d')\n",
    "    ddd2 = ddd + relativedelta(months=m)\n",
    "    return (str(ddd2))[0:10]\n",
    "\n",
    "def get_key_based_on_value_in_a_dict(dict_, value_of_interest):\n",
    "    for key, value in dict_.items():\n",
    "        if value == value_of_interest:\n",
    "            return key\n",
    "\n",
    "def get_model_number(var_, model_names):\n",
    "    if len(model_names[model_names['model_name']==var_]['model_number'])>0:\n",
    "        model_number = model_names[model_names['model_name']==var_]['model_number'].iloc[0]\n",
    "    else:\n",
    "        multiple_vars = model_names[(model_names['model_name'].apply(lambda x: ',' in x))]\n",
    "        for i in range(0, len(multiple_vars)):\n",
    "            if var_ in multiple_vars['model_name'].iloc[i]:\n",
    "                model_number = multiple_vars['model_number'].iloc[i]\n",
    "                break\n",
    "    return model_number\n",
    "\n",
    "def get_behavioural_vars(churn_based_on_behaviour_dir, date_dir):\n",
    "    vars_periods_to_look_at_thresholds_to_use = \\\n",
    "    bucket.load_csv_from_s3(file_name = churn_based_on_behaviour_dir + 'data/' + date_dir +\\\n",
    "                     '/vars_periods_to_look_at_thresholds_to_use.csv')\n",
    "\n",
    "    period_to_look_at_stopped = \\\n",
    "    vars_periods_to_look_at_thresholds_to_use[['variable_base_name', 'period_to_look_at_stopped', 'number_of_months_stopped']].\\\n",
    "    apply(lambda x: (x['variable_base_name'], x['period_to_look_at_stopped']), axis=1).tolist()\n",
    "    \n",
    "    period_to_look_at_started = \\\n",
    "    vars_periods_to_look_at_thresholds_to_use[['variable_base_name', 'period_to_look_at_started', 'number_of_months_started']].\\\n",
    "    apply(lambda x: (x['variable_base_name'], x['period_to_look_at_started']), axis=1).tolist()\n",
    "    \n",
    "\n",
    "    (all_vars, all_vars_base_names) = get_all_vars.main()\n",
    "    before_var = dict.fromkeys(all_vars_base_names.values())\n",
    "    last_X_months_var = dict.fromkeys(all_vars_base_names.values())\n",
    "    before_and_didnt_last_X_months = dict.fromkeys(all_vars_base_names.values())\n",
    "\n",
    "    for i in range(0, len(period_to_look_at_stopped)):\n",
    "        before_var[period_to_look_at_started[i][0]] = 'had_'+period_to_look_at_started[i][0]+'_before'\n",
    "        last_X_months_var[period_to_look_at_stopped[i][0]] = 'had_'+period_to_look_at_stopped[i][0]+'_'+period_to_look_at_stopped[i][1]\n",
    "        before_and_didnt_last_X_months[period_to_look_at_stopped[i][0]] = \\\n",
    "        'had_'+period_to_look_at_stopped[i][0]+'_before_and_didnt_'+period_to_look_at_stopped[i][1]\n",
    "\n",
    "    for key in before_var.keys():\n",
    "        if 'changed' in key.lower() and 'inquiry' in key.lower():\n",
    "            period_to_look_at_stopped_tmp = \\\n",
    "            vars_periods_to_look_at_thresholds_to_use[vars_periods_to_look_at_thresholds_to_use['variable_base_name']==key]['period_to_look_at_stopped'].iloc[0]\n",
    "            \n",
    "            period_to_look_at_started_tmp = \\\n",
    "            vars_periods_to_look_at_thresholds_to_use[vars_periods_to_look_at_thresholds_to_use['variable_base_name']==key]['period_to_look_at_started'].iloc[0]\n",
    "\n",
    "            before_var[key] = 'had_'+for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][key]+'_before'\n",
    "            last_X_months_var[key] = \\\n",
    "            'had_'+for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][key]+'_'+period_to_look_at_stopped_tmp\n",
    "            before_and_didnt_last_X_months[key] = \\\n",
    "            'had_'+for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][key]+'_before_and_didnt_'+period_to_look_at_stopped_tmp\n",
    "\n",
    "            \n",
    "    return (before_var, last_X_months_var, before_and_didnt_last_X_months)\n",
    "\n",
    "def get_vars_for_the_report(df): ##returns vars with 1/0 values\n",
    "    tv_vars = []\n",
    "    fixed_vars = []\n",
    "    for col in df:\n",
    "        if df[col].nunique()==2 and 1 in df[col].unique() and 0 in df[col].unique() and col not in ['event', 'premium_service_hs', 'requested_cancellation']:\n",
    "            if (len(df.drop_duplicates(['spot_id', col])) == df['spot_id'].nunique()):\n",
    "                fixed_vars.append(col)\n",
    "            else:\n",
    "                tv_vars.append(col)\n",
    "            \n",
    "    return (tv_vars, fixed_vars)\n",
    "\n",
    "def get_report_with_number_of_spots_with_var_set_to_yes(vars_of_interest, tv_vars, fixed_vars, df, df_with_last_month, last_month):\n",
    "    number_of_spots_with_var_yes = pd.DataFrame(columns = ['variable', 'spots_for_the_model', \\\n",
    "                                                       'premium_spots',\\\n",
    "                                                       'premium_spots_which_requested_cancellation',\\\n",
    "                                                       'spots_which_requested_cancellation',\\\n",
    "                                                       'spots_which_cancelled',\\\n",
    "                                                           'spots_with_variable_set_to_yes_month_before_the_event',\\\n",
    "                                                        'spots_with_variable_set_to_yes_last_month',\\\n",
    "                                                           'last_month_%_of_all_premium_spots',\\\n",
    "                                                           'last_month_%_of_all_spots',\\\n",
    "                                                      # 'number_of_spots_with_variable_set_to_yes_for_fixed_vars',\\\n",
    "                                                      #'number_of_spots_with_variable_set_to_yes_for_fixed_vars_%',\\\n",
    "                                                          ])\n",
    "                                                      \n",
    "    number_of_spots_with_var_yes['variable'] = vars_of_interest\n",
    "    number_of_spots_with_var_yes.set_index('variable', inplace = True)\n",
    "\n",
    "    fixed_vars = [x for x in vars_of_interest if x in fixed_vars]\n",
    "    tv_vars = [x for x in vars_of_interest if x in tv_vars]\n",
    "    \n",
    "    for var in vars_of_interest:\n",
    "        if var in fixed_vars:\n",
    "            number_of_spots_with_var_yes.loc[var, 'spots_with_variable_set_to_yes_for_fixed_vars'] = \\\n",
    "            df[df[var]==1]['spot_id'].nunique()\n",
    "\n",
    "        number_of_spots_with_var_yes.loc[var, 'spots_with_variable_set_to_yes_last_month'] = \\\n",
    "        df_with_last_month[(df_with_last_month['left_limit']==last_month)&\\\n",
    "                   (df_with_last_month['spot_id'].isin(df['spot_id'].unique()))&\\\n",
    "                   (df_with_last_month[var]==1)]['spot_id'].nunique()\n",
    "        \n",
    "        number_of_spots_with_var_yes.loc[var, 'spots_with_variable_set_to_yes_month_before_the_event'] = \\\n",
    "        df[(df[var]==1)&\\\n",
    "          (df['event']==True)]['spot_id'].nunique()\n",
    "\n",
    "        for_weighted_avg = df[(df[var]==1)][['left_limit', 'spot_id']].\\\n",
    "        groupby('left_limit')['spot_id'].nunique().reset_index().rename(columns = {'spot_id':'number_of_spots', 'left_limit':'month'})\n",
    "\n",
    "        for_weighted_avg['total_number_of_spots_with_var_set_to_yes'] = df[df[var]==1]['spot_id'].nunique()\n",
    "        for_weighted_avg['total_number_of_spots'] = df['spot_id'].nunique()\n",
    "        #for_weighted_avg['variable'] = var\n",
    "        for_weighted_avg = for_weighted_avg.sort_values('number_of_spots', ascending = True).reset_index(drop = True)\n",
    "        for_weighted_avg['weights'] = for_weighted_avg.index + 1\n",
    "        for_weighted_avg['weights_sum'] = for_weighted_avg['weights'].sum()\n",
    "        for_weighted_avg['number_of_spots_%'] = (for_weighted_avg['number_of_spots']/for_weighted_avg['total_number_of_spots'])*100\n",
    "        for_weighted_avg['weights'] = for_weighted_avg['weights']/for_weighted_avg['weights_sum']\n",
    "\n",
    "\n",
    "        regular_mean = for_weighted_avg['number_of_spots'].mean()\n",
    "        regular_mean_perc = for_weighted_avg['number_of_spots_%'].mean()\n",
    "\n",
    "        weighted_mean = (for_weighted_avg['number_of_spots']*for_weighted_avg['weights']).sum()\n",
    "        weighted_mean_perc = (for_weighted_avg['number_of_spots_%']*for_weighted_avg['weights']).sum()\n",
    "\n",
    "        number_of_spots_with_var_yes.loc[var, 'spots_with_variable_set_to_yes_regular_mean'] = round(regular_mean)\n",
    "        number_of_spots_with_var_yes.loc[var, '%_of_total_spots_regular_mean'] = round(regular_mean_perc, 2)\n",
    "        number_of_spots_with_var_yes.loc[var, 'spots_with_variable_set_to_yes_weighted_mean'] = round(weighted_mean)\n",
    "        number_of_spots_with_var_yes.loc[var, '%_of_total_spots_weighted_mean'] = round(weighted_mean_perc, 2)\n",
    "\n",
    "    number_of_spots_with_var_yes['spots_for_the_model'] = df_timeline_with_add_fields['spot_id'].nunique()\n",
    "    number_of_spots_with_var_yes['premium_spots'] = df_timeline_with_add_fields[df_timeline_with_add_fields['premium_service_hs']==True]['spot_id'].nunique()\n",
    "    number_of_spots_with_var_yes['premium_spots_which_requested_cancellation'] = \\\n",
    "    df_timeline_with_add_fields[(df_timeline_with_add_fields['premium_service_hs']==True)&\\\n",
    "                               (df_timeline_with_add_fields['requested_cancellation']==True)]['spot_id'].nunique()\n",
    "    number_of_spots_with_var_yes['spots_which_requested_cancellation'] = \\\n",
    "    df_timeline_with_add_fields[df_timeline_with_add_fields['requested_cancellation']==True]['spot_id'].nunique()\n",
    "    number_of_spots_with_var_yes['spots_which_cancelled'] = \\\n",
    "    df_timeline_with_add_fields[df_timeline_with_add_fields['premium_service_hs']==False]['spot_id'].nunique()\n",
    "    \n",
    "\n",
    "    number_of_spots_with_var_yes['last_month_%_of_all_spots'] = \\\n",
    "    round((number_of_spots_with_var_yes['spots_with_variable_set_to_yes_last_month']/number_of_spots_with_var_yes['spots_for_the_model'])*100, 2)\n",
    "\n",
    "    number_of_spots_with_var_yes['last_month_%_of_all_premium_spots'] = \\\n",
    "    round((number_of_spots_with_var_yes['spots_with_variable_set_to_yes_last_month']/number_of_spots_with_var_yes['premium_spots'])*100, 2)\n",
    "    \n",
    "    return number_of_spots_with_var_yes\n",
    "\n",
    "\n",
    "# read the yaml file with a list of parameters needed for the report\n",
    "with open(r'./parameters/started_doing_something_report_parameters.yaml') as file:\n",
    "    parameters = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "date_of_analysis = parameters['date_of_analysis']\n",
    "date_dir = date_of_analysis.replace('-', '_')\n",
    "### name of the data directory ###\n",
    "churn_based_on_behaviour_dir = parameters['churn_based_on_behaviour_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### base columns ##### \n",
    "base_cols = ['spot_id',\\\n",
    "            'time',\\\n",
    "            'event']\n",
    "\n",
    "\n",
    "data_sets = [#'ALL_spots_with_CB_cancellation_confirmed',\\\n",
    "             'ALL_spots_with_CB_cancellation_requested',\\\n",
    "             #'ALL_spots_wo_CB_cancellation_confirmed', \\\n",
    "             #'ALL_spots_wo_CB_cancellation_requested',\\\n",
    "            # 'CAN_CANCEL_spots_with_CB_cancellation_confirmed',\\\n",
    "            # 'CAN_CANCEL_spots_with_CB_cancellation_requested',\\\n",
    "             #'CAN_CANCEL_spots_wo_CB_cancellation_confirmed', \\\n",
    "             'CAN_CANCEL_spots_wo_CB_cancellation_requested']\n",
    "\n",
    "for data_set_name in data_sets:\n",
    "\n",
    "    with open(r'./parameters/data_sets.yaml') as file:\n",
    "        data_sets_parameters = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    spots_set = data_sets_parameters[data_set_name]['spots_set']\n",
    "    with_wo_CB = data_sets_parameters[data_set_name]['with_wo_CB']\n",
    "    event_date_full_name = data_sets_parameters[data_set_name]['event_date_type']\n",
    "\n",
    "    if with_wo_CB == 'with_CB':\n",
    "        with_wo_CB_boolean = True\n",
    "    else:\n",
    "        with_wo_CB_boolean = False\n",
    "\n",
    "    if event_date_full_name == 'cancellation_requested':\n",
    "        event_date = 'canc_req'\n",
    "    elif event_date_full_name == 'cancellation_confirmed':\n",
    "        event_date = 'canc_conf'\n",
    "\n",
    "    ##### Model 0: all variables - prepare data for the model ####\n",
    "    cols_to_use = read_a_combination_of_variables.\\\n",
    "    main(model_number=0, dir_name='combinations_of_variables_that_are_not_dependent/')\n",
    "    #### get behavioural variables ####\n",
    "    (variables_to_use_for_the_model, did_something_last_month_vars, did_something_before_and_didnt_last_month_vars) = \\\n",
    "    get_started_doing_something_variables.main(date_of_analysis=date_of_analysis, variables_to_use_for_the_model=cols_to_use)\n",
    "\n",
    "    (variables_to_use_for_the_model, did_something_before_vars, did_something_last_month_vars) = \\\n",
    "    get_stopped_doing_something_variables.main(date_of_analysis=date_of_analysis, variables_to_use_for_the_model=cols_to_use)\n",
    "\n",
    "\n",
    "    cols = base_cols + variables_to_use_for_the_model + did_something_before_vars + \\\n",
    "    did_something_before_and_didnt_last_month_vars + did_something_last_month_vars\n",
    "\n",
    "    #### get data for the model ###\n",
    "    (data, base_df, df_timeline_all_vars) = \\\n",
    "    prepare_for_the_models.get_data_for_the_MV_Cox_model(date_of_analysis=date_of_analysis, spots_set=spots_set, \\\n",
    "                                with_wo_CB=with_wo_CB, event_date=event_date, columns=cols, data_dir=churn_based_on_behaviour_dir,\\\n",
    "                                C = 100)\n",
    "\n",
    "    additional_fields = ['limits', 'left_limit', 'right_limit', 'premium_service_hs', 'requested_cancellation', 'end', 'cancellation_requested']\n",
    "    df_timeline_with_add_fields = df_timeline_all_vars.merge(data[['spot_id', 'time']+additional_fields].rename(columns = {'time':'stop'}),\\\n",
    "                                   on = ['spot_id', 'stop'])\n",
    "    df_timeline_with_add_fields['their_own_website_yes'] = 0\n",
    "    df_timeline_with_add_fields.loc[(df_timeline_with_add_fields['their_own_website_dontKnow']==0)&\\\n",
    "                                   (df_timeline_with_add_fields['their_own_website_no']==0), 'their_own_website_yes'] = 1\n",
    "\n",
    "    (tv_vars, fixed_vars) = get_vars_for_the_report(df_timeline_with_add_fields)\n",
    "    (before_var, last_X_months_var, before_and_didnt_last_X_months) = \\\n",
    "    get_behavioural_vars(churn_based_on_behaviour_dir=churn_based_on_behaviour_dir,\\\n",
    "                           date_dir=date_dir)\n",
    "\n",
    "    with open(r'./parameters/base_vars_for_the_num_of_vars_set_to_yes_export.yaml') as file:\n",
    "        base_names_of_vars_of_interest = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        base_names_of_vars_of_interest = \\\n",
    "        base_names_of_vars_of_interest['base_names_of_vars_of_interest']\n",
    "\n",
    "    vars_of_interest = []\n",
    "    for base_var in base_names_of_vars_of_interest:\n",
    "        vars_of_interest.append(before_var[base_var])\n",
    "        vars_of_interest.append(last_X_months_var[base_var])\n",
    "        vars_of_interest.append(before_and_didnt_last_X_months[base_var])\n",
    "\n",
    "    number_of_spots_with_var_yes = \\\n",
    "    get_report_with_number_of_spots_with_var_set_to_yes(vars_of_interest=vars_of_interest,\\\n",
    "                                                        tv_vars=tv_vars, fixed_vars=fixed_vars, \\\n",
    "                                                        df=df_timeline_with_add_fields,\\\n",
    "                                                        df_with_last_month=data, last_month=add_month(date_of_analysis, -1))\n",
    "\n",
    "    number_of_spots_with_var_yes.\\\n",
    "    to_csv('data/'+date_dir+'/exports/number_of_spots_with_var_set_to_yes_'+data_set_name+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
