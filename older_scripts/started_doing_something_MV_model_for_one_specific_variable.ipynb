{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spots that are always excluded:\n",
    "##### Test spots\n",
    "##### Spots marked as problematic\n",
    "##### Suscpicious for analysis == 'Yes' spots\n",
    "##### Fake Sale spots: This means that Reason for Cancelling Survey is any combination which contains 'Fake Sale'\n",
    "##### Spots whose start date was before 2018\n",
    "\n",
    "\n",
    "## CAN CANCEL:\n",
    "##### Spots which cancelled more than 2 months before their Available Cancellation Date are excluded\n",
    "##### Spots whose Available Cancellation Date is 2 or more months after the date of analysis\n",
    "##### Months during which spots couldn't have cancelled according to the above conditions\n",
    "\n",
    "## wo CB sets:\n",
    "##### Closed Business, Sold Business and Non-payment spots are excluded. This means Reason for Cancelling Survey is any combination which contains 'Closed Business', 'Closed/Sold Business', 'Sold Business', 'Sold/Closed Business' or 'Non-payment'\n",
    "## canc conf event\n",
    "##### Spots for which Date Cancellation Confirmed is more than 60 days after Date Cancellation Requested\n",
    "\n",
    "#### ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import get_started_doing_something_variables\n",
    "import prepare_for_the_models\n",
    "import fit_tv_cox_models\n",
    "#import read_vars_for_separate_models_for_dependent_vars\n",
    "import read_a_combination_of_variables\n",
    "import get_all_vars\n",
    "import yaml\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from helpers.s3_bucket_utils import S3BucketUtils\n",
    "from helpers import settings\n",
    "\n",
    "bucket = S3BucketUtils()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "with open(r'./parameters/for_properly_used_inquiries_vars.yaml') as file:\n",
    "    for_properly_used_inquiries_vars = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "def get_key_based_on_value_in_a_dict(dict_, value_of_interest):\n",
    "    for key, value in dict_.items():\n",
    "        if value == value_of_interest:\n",
    "            return key\n",
    "\n",
    "def get_model_number(var_, model_names):\n",
    "    if len(model_names[model_names['model_name']==var_]['model_number'])>0:\n",
    "        model_number = model_names[model_names['model_name']==var_]['model_number'].iloc[0]\n",
    "    else:\n",
    "        multiple_vars = model_names[(model_names['model_name'].apply(lambda x: ',' in x))]\n",
    "        for i in range(0, len(multiple_vars)):\n",
    "            if var_ in multiple_vars['model_name'].iloc[i]:\n",
    "                model_number = multiple_vars['model_number'].iloc[i]\n",
    "                break\n",
    "    return model_number\n",
    "\n",
    "def get_pairs_of_variables(churn_based_on_behaviour_dir, date_dir, model_type):\n",
    "    vars_periods_to_look_at_thresholds_to_use = \\\n",
    "    bucket.load_csv_from_s3(file_name = churn_based_on_behaviour_dir + 'data/' + date_dir +\\\n",
    "                     '/vars_periods_to_look_at_thresholds_to_use.csv')\n",
    "\n",
    "    period_to_look_at =\\\n",
    "    vars_periods_to_look_at_thresholds_to_use[['variable_base_name', 'period_to_look_at', 'number_of_months']].\\\n",
    "    apply(lambda x: (x['variable_base_name'], x['period_to_look_at']), axis=1).tolist()\n",
    "\n",
    "\n",
    "    (all_vars, all_vars_base_names) = get_all_vars.main()\n",
    "    first_var = dict.fromkeys(all_vars_base_names.values())\n",
    "    second_var = dict.fromkeys(all_vars_base_names.values())\n",
    "\n",
    "    if model_type == 'started_doing_something':\n",
    "        for i in range(0, len(period_to_look_at)):\n",
    "            first_var[period_to_look_at[i][0]] = 'had_'+period_to_look_at[i][0]+'_'+period_to_look_at[i][1]\n",
    "            second_var[period_to_look_at[i][0]] = \\\n",
    "            'had_'+period_to_look_at[i][0]+'_before_and_didnt_'+period_to_look_at[i][1]\n",
    "\n",
    "        for key in first_var.keys():\n",
    "            if 'changed' in key.lower() and 'inquiry' in key.lower():\n",
    "                period_to_look_at_tmp = vars_periods_to_look_at_thresholds_to_use[vars_periods_to_look_at_thresholds_to_use['variable_base_name']==\\\n",
    "                                                                                 key]['period_to_look_at'].iloc[0]\n",
    "\n",
    "                first_var[key] = 'had_'+for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][key]+'_'+period_to_look_at_tmp\n",
    "        for key in second_var.keys():\n",
    "            if 'changed' in key.lower() and 'inquiry' in key.lower():\n",
    "                period_to_look_at_tmp = vars_periods_to_look_at_thresholds_to_use[vars_periods_to_look_at_thresholds_to_use['variable_base_name']==\\\n",
    "                                                                                 key]['period_to_look_at'].iloc[0]\n",
    "\n",
    "                second_var[key] = 'had_'+for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][key]+'_before_and_didnt_'+period_to_look_at_tmp\n",
    "\n",
    "    elif model_type == 'stopped_doing_something':\n",
    "        for i in range(0, len(period_to_look_at)):\n",
    "            first_var[period_to_look_at[i][0]] = 'had_'+period_to_look_at[i][0]+'_before'\n",
    "            second_var[period_to_look_at[i][0]] = 'had_'+period_to_look_at[i][0]+'_'+period_to_look_at[i][1]\n",
    "\n",
    "        for key in first_var.keys():\n",
    "            if 'changed' in key.lower() and 'inquiry' in key.lower():\n",
    "                period_to_look_at_tmp = vars_periods_to_look_at_thresholds_to_use[vars_periods_to_look_at_thresholds_to_use['variable_base_name']==\\\n",
    "                                                                                 key]['period_to_look_at'].iloc[0]\n",
    "\n",
    "                first_var[key] = 'had_'+for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][key]+'_before'\n",
    "        for key in second_var.keys():\n",
    "            if 'changed' in key.lower() and 'inquiry' in key.lower():\n",
    "                period_to_look_at_tmp = vars_periods_to_look_at_thresholds_to_use[vars_periods_to_look_at_thresholds_to_use['variable_base_name']==\\\n",
    "                                                                                 key]['period_to_look_at'].iloc[0]\n",
    "\n",
    "                second_var[key] = 'had_'+for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][key]+'_'+period_to_look_at_tmp\n",
    "\n",
    "\n",
    "    return (first_var, second_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable we're interested in: had_catering_submissions_last_3_months\n",
      "Without properly used inquiries variables (Yes/No)? Yes\n"
     ]
    }
   ],
   "source": [
    "# read the yaml file with a list of parameters needed for the report\n",
    "with open(r'./parameters/started_doing_something_report_parameters.yaml') as file:\n",
    "    parameters = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "date_of_analysis = parameters['date_of_analysis']\n",
    "date_dir = date_of_analysis.replace('-', '_')\n",
    "### name of the data directory ###\n",
    "churn_based_on_behaviour_dir = parameters['churn_based_on_behaviour_dir']\n",
    "### penalizer value when fitting the models ###\n",
    "penalizer = parameters['penalizer']\n",
    "### model type ###\n",
    "model_type = parameters['model_type']\n",
    "### coefficient and p values when dropping unsignificant variables ###\n",
    "coefficient_limit_for_numerical_vars = parameters['coefficient_limit_for_numerical_vars']\n",
    "coefficient_limit_for_cat_vars = parameters['coefficient_limit_for_cat_vars']\n",
    "p_limit = parameters['p_limit']\n",
    "additional_higher_p_limit = parameters['additional_higher_p_limit']\n",
    "additional_lower_p_limit = parameters['additional_lower_p_limit']\n",
    "\n",
    "var_of_interest = input(\"Variable we're interested in: \")\n",
    "# had_private_parties_submissions_last_2_months\n",
    "\n",
    "\n",
    "without_properly_used_vars = input('Without properly used inquiries variables (Yes/No)? ')\n",
    "if without_properly_used_vars == 'Yes':\n",
    "    without_properly_used_vars = True\n",
    "    combinations_of_vars_dir = 'combinations_of_variables_that_are_not_dependent/combinations_and_names_without_properly_used_inquiries_vars'\n",
    "elif without_properly_used_vars == 'No':\n",
    "    without_properly_used_vars = False\n",
    "    combinations_of_vars_dir = 'combinations_of_variables_that_are_not_dependent'\n",
    "    \n",
    "    \n",
    "(first_var, second_var) = \\\n",
    "get_pairs_of_variables(churn_based_on_behaviour_dir='churn_analysis_based_on_behaviour/', date_dir=date_dir,\\\n",
    "                       model_type=model_type)\n",
    "\n",
    "if var_of_interest in first_var.values():\n",
    "    base_var_ = get_key_based_on_value_in_a_dict(dict_=first_var, value_of_interest=var_of_interest)\n",
    "elif var_of_interest in second_var.values():\n",
    "    base_var_ = get_key_based_on_value_in_a_dict(dict_=second_var, value_of_interest=var_of_interest)\n",
    "else:\n",
    "    base_var_ = var_of_interest\n",
    "    \n",
    "if 'properly' in var_of_interest:\n",
    "    base_var_ = for_properly_used_inquiries_vars['changed_inquiry_status_to_properly_used'][base_var_]\n",
    "    \n",
    "model_names = \\\n",
    "bucket.load_csv_from_s3(file_name='churn_analysis_based_on_behaviour/'+combinations_of_vars_dir+'/model_names.csv')\n",
    "model_number = get_model_number(var_=base_var_, model_names=model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### base columns ##### \n",
    "base_cols = ['spot_id',\\\n",
    "            'time',\\\n",
    "            'event']\n",
    "for data_set_name in ['ALL_spots_with_CB_cancellation_confirmed', 'ALL_spots_with_CB_cancellation_requested',\\\n",
    "                     'ALL_spots_wo_CB_cancellation_confirmed', 'ALL_spots_wo_CB_cancellation_requested',\\\n",
    "                     'CAN_CANCEL_spots_with_CB_cancellation_confirmed', 'CAN_CANCEL_spots_with_CB_cancellation_requested',\\\n",
    "                     'CAN_CANCEL_spots_wo_CB_cancellation_confirmed', 'CAN_CANCEL_spots_wo_CB_cancellation_requested']:\n",
    "    with open(r'./parameters/data_sets.yaml') as file:\n",
    "        data_sets_parameters = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    spots_set = data_sets_parameters[data_set_name]['spots_set']\n",
    "    with_wo_CB = data_sets_parameters[data_set_name]['with_wo_CB']\n",
    "    event_date_full_name = data_sets_parameters[data_set_name]['event_date_type']\n",
    "\n",
    "    if with_wo_CB == 'with_CB':\n",
    "        with_wo_CB_boolean = True\n",
    "    else:\n",
    "        with_wo_CB_boolean = False\n",
    "\n",
    "    if event_date_full_name == 'cancellation_requested':\n",
    "        event_date = 'canc_req'\n",
    "    elif event_date_full_name == 'cancellation_confirmed':\n",
    "        event_date = 'canc_conf'\n",
    "        \n",
    "    ##### Model 0: all variables - prepare data for the model ####\n",
    "    cols_to_use = read_a_combination_of_variables.\\\n",
    "    main(model_number=0, dir_name=combinations_of_vars_dir+'/')\n",
    "    #### get behavioural variables ####\n",
    "    (variables_to_use_for_the_model, did_something_last_month_vars, did_something_before_and_didnt_last_month_vars) = \\\n",
    "    get_started_doing_something_variables.main(date_of_analysis=date_of_analysis, variables_to_use_for_the_model=cols_to_use)\n",
    "    cols = base_cols + variables_to_use_for_the_model + \\\n",
    "    did_something_before_and_didnt_last_month_vars + did_something_last_month_vars\n",
    "\n",
    "\n",
    "    #### get data for the model ###\n",
    "    (data, base_df, df_timeline_all_vars) = \\\n",
    "    prepare_for_the_models.get_data_for_the_MV_Cox_model(date_of_analysis=date_of_analysis, spots_set=spots_set, \\\n",
    "                                with_wo_CB=with_wo_CB, event_date=event_date, columns=cols, data_dir=churn_based_on_behaviour_dir,\\\n",
    "                                C = 100)\n",
    "    \n",
    "    \n",
    "    cols_to_use = read_a_combination_of_variables.\\\n",
    "    main(model_number=model_number, dir_name=combinations_of_vars_dir+'/')\n",
    "    \n",
    "    model_name = \\\n",
    "    read_a_combination_of_variables.get_model_names(model_number=model_number, \\\n",
    "                                                    dir_name=combinations_of_vars_dir+'/')\n",
    "    \n",
    "     #### get behavioural variables ####\n",
    "    (variables_to_use_for_the_model, did_something_last_month_vars, did_something_before_and_didnt_last_month_vars) = \\\n",
    "    get_started_doing_something_variables.main(date_of_analysis=date_of_analysis, variables_to_use_for_the_model=cols_to_use)\n",
    "    cols = variables_to_use_for_the_model + \\\n",
    "    did_something_before_and_didnt_last_month_vars + did_something_last_month_vars\n",
    "\n",
    "    #### data for the model ###\n",
    "    df_timeline = df_timeline_all_vars.copy()\n",
    "    vars_that_stay = ['spot_id', 'start', 'stop', 'event']+\\\n",
    "    [x for x in cols if x not in base_cols]+\\\n",
    "    [x for x in df_timeline.columns if 'spot_category_' in x or 'metro_area_' in x]\n",
    "    df_timeline.drop([x for x in df_timeline.columns if x not in vars_that_stay], axis = 1, inplace = True)\n",
    "\n",
    "    ### variables to skip ###\n",
    "    df_timeline.isnull().sum().sum() #OK\n",
    "    skip_vars = list((df_timeline!=0).sum()[(df_timeline!=0).sum()==0].index)\n",
    "    \n",
    "    (ctv, all_summaries, conditions_described) = \\\n",
    "    fit_tv_cox_models.fit_the_models_and_return_all_intermediate_results(df_timeline=df_timeline, base_df=base_df, \\\n",
    "                                                         date_of_analysis=date_of_analysis, model_type=model_type, \\\n",
    "                                                         variables_to_use_for_the_model=cols_to_use,\\\n",
    "                                                         coefficient_limit_for_numerical_vars=coefficient_limit_for_numerical_vars, \\\n",
    "                                                         coefficient_limit_for_cat_vars=coefficient_limit_for_cat_vars, p_limit=p_limit, \\\n",
    "                                                         additional_higher_p_limit=additional_higher_p_limit, \\\n",
    "                                                         additional_lower_p_limit=additional_lower_p_limit,\\\n",
    "                                                         skip_vars=skip_vars, penalizer=penalizer)\n",
    "\n",
    "    for condition in all_summaries.keys():\n",
    "#         print(condition)\n",
    "#         print(len(all_summaries[condition]))\n",
    "        if without_properly_used_vars == True:\n",
    "            fit_tv_cox_models.save_results_for_a_specific_variable(df = all_summaries[condition].reset_index(),\\\n",
    "                                            condition=condition,\\\n",
    "                                            var_of_interest=var_of_interest,\\\n",
    "                                            date_of_analysis=date_of_analysis,\\\n",
    "                                            data_dir=churn_based_on_behaviour_dir,\\\n",
    "                                            dir_name='exports/coefficients_and_pvalues',\\\n",
    "                                            results_name='without_properly_used_vars_coef_and_pvalues',\\\n",
    "                                            spots_set=spots_set,\\\n",
    "                                            with_wo_CB=with_wo_CB,\\\n",
    "                                            event_date_type=event_date_full_name,\\\n",
    "                                            model_type=model_type)\n",
    "        else:\n",
    "            fit_tv_cox_models.save_results_for_a_specific_variable(df = all_summaries[condition].reset_index(),\\\n",
    "                                            condition=condition,\\\n",
    "                                            var_of_interest=var_of_interest,\\\n",
    "                                            date_of_analysis=date_of_analysis,\\\n",
    "                                            data_dir=churn_based_on_behaviour_dir,\\\n",
    "                                            dir_name='exports/coefficients_and_pvalues',\\\n",
    "                                            results_name='with_properly_used_vars_coef_and_pvalues',\\\n",
    "                                            spots_set=spots_set,\\\n",
    "                                            with_wo_CB=with_wo_CB,\\\n",
    "                                            event_date_type=event_date_full_name,\\\n",
    "                                            model_type=model_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
